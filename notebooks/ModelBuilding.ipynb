{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc9c29f7-6d91-40d7-bb15-c194693d4c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7967479674796748\n",
      "Confusion Matrix:\n",
      "[[21 22]\n",
      " [ 3 77]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.49      0.63        43\n",
      "           1       0.78      0.96      0.86        80\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.83      0.73      0.74       123\n",
      "weighted avg       0.81      0.80      0.78       123\n",
      "\n",
      "Merged data saved as model_training.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../src')  # Add the src directory to the system path\n",
    "\n",
    "from data_preprocessing import load_data, handle_missing_values\n",
    "from feature_engineering import add_total_income_feature\n",
    "from model_training import encode_categorical_variables, train_model\n",
    "from predictions import make_predictions, save_predictions\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the preprocessed data\n",
    "train_data = pd.read_csv('../data/train_cleaned.csv')\n",
    "test_data = pd.read_csv('../data/test_cleaned.csv')\n",
    "\n",
    "# Combine train and test data for consistent encoding\n",
    "combined_data = pd.concat([train_data, test_data], axis=0, ignore_index=True)\n",
    "\n",
    "# Feature Engineering: Add Total Income feature\n",
    "combined_data = add_total_income_feature(combined_data)\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "label_encoders = {}\n",
    "for column in combined_data.select_dtypes(include=['object']):\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    combined_data[column] = label_encoders[column].fit_transform(combined_data[column])\n",
    "\n",
    "# Separate back into train and test data\n",
    "train_data = combined_data.iloc[:train_data.shape[0], :]\n",
    "test_data = combined_data.iloc[train_data.shape[0]:, :]\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = train_data.drop(columns=['Loan_Status'])\n",
    "y = train_data['Loan_Status']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "test_data_features = test_data.drop(columns=['Loan_Status'])  # Exclude target variable\n",
    "test_data_scaled = scaler.transform(test_data_features)\n",
    "\n",
    "# Model Building: Train the Random Forest Classifier\n",
    "model, accuracy, confusion, classification_rep = train_model(X_train_scaled, y_train, X_val_scaled, y_val)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{confusion}')\n",
    "print(f'Classification Report:\\n{classification_rep}')\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(model, '../model/random_forest_model(1).pkl')\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = make_predictions(model, test_data_scaled)\n",
    "\n",
    "# Prepare the submission file\n",
    "save_predictions(test_predictions, test_data_features, filename='../data/loan_predictions.csv')\n",
    "\n",
    "# Load the CSV files for merging\n",
    "loan_predictions = pd.read_csv('../data/loan_predictions.csv')\n",
    "test_cleaned = pd.read_csv('../data/test_cleaned.csv')\n",
    "\n",
    "# Drop the 'Loan_ID' column from loan_predictions\n",
    "loan_predictions = loan_predictions.drop(columns=['Loan_ID'])\n",
    "\n",
    "# Add remaining columns to test_cleaned\n",
    "merged_data = pd.concat([test_cleaned, loan_predictions], axis=1)\n",
    "\n",
    "# Save the merged data to model_training.csv\n",
    "merged_data.to_csv('../data/model_training.csv', index=False)\n",
    "\n",
    "print(\"Merged data saved as model_training.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c009b40-e7b6-45ad-80b3-570576fe93b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found at ../data/model_training.csv\n",
      "Class distribution in training set: [ 70 297]\n",
      "Model saved at ../model/random_forest_model.pkl\n",
      "Label encoders saved at ../model/label_encoders.pkl\n",
      "Scaler saved at ../model/scaler.pkl\n",
      "Status encoder saved at ../model/status_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "#Buliding the model\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Verify and update file path\n",
    "file_path = '../data/model_training.csv'\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"File not found at {file_path}\")\n",
    "else:\n",
    "    print(f\"File found at {file_path}\")\n",
    "\n",
    "# Load training data\n",
    "train_data = pd.read_csv(file_path)\n",
    "\n",
    "# Identify categorical columns and numeric columns\n",
    "categorical_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area']\n",
    "numeric_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    train_data[column] = le.fit_transform(train_data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Encode target variable\n",
    "le_status = LabelEncoder()\n",
    "train_data['Loan_Status'] = le_status.fit_transform(train_data['Loan_Status'])\n",
    "\n",
    "# Separate features and target\n",
    "X = train_data.drop(columns=['Loan_ID', 'Loan_Status'])\n",
    "y = train_data['Loan_Status']\n",
    "\n",
    "# Standardize numeric variables\n",
    "scaler = StandardScaler()\n",
    "X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Output class distribution\n",
    "print(f\"Class distribution in training set: {np.bincount(y)}\")\n",
    "\n",
    "# Save the model\n",
    "model_save_path = '../model/random_forest_model.pkl'\n",
    "joblib.dump(model, model_save_path)\n",
    "print(f\"Model saved at {model_save_path}\")\n",
    "\n",
    "# Save the label encoders and scaler\n",
    "encoders_save_path = '../model/label_encoders.pkl'\n",
    "joblib.dump(label_encoders, encoders_save_path)\n",
    "print(f\"Label encoders saved at {encoders_save_path}\")\n",
    "\n",
    "scaler_save_path = '../model/scaler.pkl'\n",
    "joblib.dump(scaler, scaler_save_path)\n",
    "print(f\"Scaler saved at {scaler_save_path}\")\n",
    "\n",
    "# Save the label encoder for the target variable\n",
    "status_encoder_save_path = '../model/status_encoder.pkl'\n",
    "joblib.dump(le_status, status_encoder_save_path)\n",
    "print(f\"Status encoder saved at {status_encoder_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3cbbe-6eaf-4747-a3d8-f7a4b23f3b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
